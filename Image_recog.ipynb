{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Made by Group 4 \n",
    "\n",
    "\n",
    "1.sk rehan ahamed\n",
    "\n",
    "2.Shabnam Parween\n",
    "\n",
    "3.Arisha Aftab\n",
    "\n",
    "4.Hasibul Mondal\n",
    "\n",
    "5.Samadur Khan\n",
    "\n",
    "6.Maruf Hassan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "video=cv2.VideoCapture(0)#Method to create video Capture Object.It Will Trigger the Camera.\n",
    "# 0 - to use build in camera,1 - to use external camera.\n",
    "#VIdeoCapture(0)- it reads the first image/frame of  the video.\n",
    "\n",
    "\n",
    "# load a sample pic and learn how to recognize it.\n",
    "\n",
    "\n",
    "\n",
    "shabnam_image = face_recognition.load_image_file(\"F:\\\\python project\\\\Known faces\\\\Shabnam.jpg\")# load the jpg file numpy array\n",
    "shabnam_face_encoding = face_recognition.face_encodings(shabnam_image)[0]# list.\n",
    "# face encoding of each face ,it return a list of encoding because a image may contain more than one face.\n",
    " #Histogram of Oriented Gradients \n",
    "\n",
    "hasibul_image = face_recognition.load_image_file(\"F:\\python project\\Known faces\\\\Hasibul.jpg\")\n",
    "hasibul_face_encoding = face_recognition.face_encodings(hasibul_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rehan_image = face_recognition.load_image_file(\"F:\\\\python project\\\\Known faces\\\\rehan.jpg\")\n",
    "rehan_face_encoding = face_recognition.face_encodings(rehan_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "maruf_image = face_recognition.load_image_file(\"F:\\\\python project\\\\Known faces\\\\Maruf.jpg\")\n",
    "maruf_face_encoding = face_recognition.face_encodings(maruf_image)[0]\n",
    "\n",
    "\n",
    "Arisha_image = face_recognition.load_image_file(\"F:\\\\python project\\\\Known faces\\\\arisha.jpeg\")\n",
    "Arisha_face_encoding = face_recognition.face_encodings(Arisha_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "#creatw array of know faces and encodings\n",
    "\n",
    "known_face_encodings = [\n",
    "   \n",
    "    maruf_face_encoding,\n",
    "    rehan_face_encoding,\n",
    "    hasibul_face_encoding,\n",
    "    shabnam_face_encoding,\n",
    "    Arisha_face_encoding,\n",
    "    \n",
    "]\n",
    "known_face_names = [\n",
    "    \n",
    "    \"maruf\",\n",
    "    \"rehan\",\n",
    "    \"Hasibul\",\n",
    "    \"Shabnam\",\n",
    "    \"Arisha\",\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a single frame of video.\n",
    "    face_names=[]\n",
    "    lval=[]\n",
    "    rit,frame=video.read()\n",
    "    #rit- boolean type object to detect if python is able to read the videoCapture object.(true / False)\n",
    "    #frame- numpy array ...represent the first image that the video Captures.\n",
    "    \n",
    "    \n",
    "    \n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "    rgb_small_frame=small_frame[:,:,:: -1]\n",
    "    #rezise frame for faster face recogniton processing.\n",
    "    face_locations=face_recognition.face_locations(rgb_small_frame,)\n",
    "    #Find all the faces in the image using the default HOG-based model.\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "     # find the faces and face enoding in the current current frame of the video\n",
    "    \n",
    "   \n",
    "     \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        # checked for match with known faces .\n",
    "        #matches is a array of true /false\n",
    "        \n",
    "        if True in matches:\n",
    "                   first_match_index = matches.index(True)\n",
    "                   name = known_face_names[first_match_index]\n",
    "                    \n",
    "                        \n",
    "        \n",
    "            \n",
    "               \n",
    "        \n",
    "            \n",
    "                   #calculating the face_distances.\n",
    "                   face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                   face_match_threshold=0.6\n",
    "                   for face_distance in face_distances:\n",
    "                        \n",
    "                        \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "                        if face_distance < face_match_threshold:\n",
    "            \n",
    "                             range = face_match_threshold\n",
    "                             linear_val = 1.0 - (face_distance / (range * 2.0))\n",
    "                             l=round((linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2)))*100)\n",
    "                             l=str(l)\n",
    "                                       \n",
    "            \n",
    "        else:\n",
    "            name=\"Unknown\"\n",
    "            l=\"Null\"\n",
    "            \n",
    "            \n",
    "                             \n",
    "                                      \n",
    "        \n",
    "        lval.append(l)    \n",
    "        face_names.append(name)\n",
    "     \n",
    "     # display the result    \n",
    "    for (top, right, bottom, left), name,l in zip(face_locations, face_names,lval):\n",
    "        \n",
    "        \n",
    "        #draw a box\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        \n",
    "        #put name of the face and percentage\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.50, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, l+\"%\", (left + 80, bottom - 6), font, 0.50, (255, 255, 255), 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "   \n",
    "\n",
    "    cv2.imshow(\"capture\",frame)# captures the first frame/image of the video.\n",
    "    key=cv2.waitKey(1) # generate a new frame after every 1 milliseconds.\n",
    "    if key == ord(\"q\"): # once we enter 'q' window will be destroyed\n",
    "        break\n",
    "        \n",
    "           \n",
    "\n",
    "video.release()# release the camera in some milliseconds.\n",
    "cv2.destroyAllWindows()# destroy all the windows according to waitKey parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
